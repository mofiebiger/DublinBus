{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and importing modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:46.639451Z",
     "start_time": "2019-07-23T13:42:45.962946Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "\n",
    "import requests as r\n",
    "import pandas as pd\n",
    "import seaborn as s\n",
    "import numpy as np\n",
    "\n",
    "import holidays\n",
    "ie_holidays = holidays.Ireland()\n",
    "\n",
    "import postgres\n",
    "import gmaps\n",
    "import googlemaps\n",
    "import json\n",
    "import config\n",
    "import math\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "\n",
    "from tqdm import tnrange, tqdm_notebook, tqdm\n",
    "\n",
    "\n",
    "from tqdm._tqdm_notebook import tqdm_notebook as tdnot\n",
    "tdnot.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:46.946372Z",
     "start_time": "2019-07-23T13:42:46.939715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from '/media/storage/College/S3/Github/DublinBus/Analytics/config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(postgres.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:47.262528Z",
     "start_time": "2019-07-23T13:42:47.259779Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Export the number of stops on each lineid for basic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in all lineids from teh database and store in a text file.\n",
    "\n",
    "\n",
    "# lineids = postgres.query(\"Select distinct(lineid) from combined;\", tunnel=True)\n",
    "\n",
    "# q = dict()\n",
    "# for lidx in tnrange(len(lineids)):\n",
    "    \n",
    "#     lid = lineids[lidx]\n",
    "#     q[lid[0]] = postgres.query(\"SELECT MAX(progrnumber) FROM combined WHERE lineid='%s';\" % str(lid[0]), tunnel=True)\n",
    "    \n",
    "# with open(\"stops_per_line.txt\",'w') as f:\n",
    "#     f.write(json.dumps(q))\n",
    "# f.closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with open(\"stops_per_line.txt\",'r') as g:\n",
    "    max_stops_per_line = json.loads(g.readlines()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:51.621496Z",
     "start_time": "2019-07-23T13:42:48.121000Z"
    }
   },
   "outputs": [],
   "source": [
    "data = postgres.query(\"SELECT * FROM combined;\", tunnel=True)\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# data = pd.read_csv(\"stored_queries/combined145.csv\")\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:51.715158Z",
     "start_time": "2019-07-23T13:42:51.691891Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.columns = ['dayofservice','tripid','lineid','direction','progrnumber','stopid','plannedDEP','plannedARR','actualDEP','actualARR','routeid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:52.715766Z",
     "start_time": "2019-07-23T13:42:51.774571Z"
    }
   },
   "outputs": [],
   "source": [
    "data.dayofservice = pd.to_datetime(data.dayofservice.loc[:])\n",
    "data.lineid = data.lineid.astype('category')\n",
    "data.routeid= data.routeid.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:54.073579Z",
     "start_time": "2019-07-23T13:42:52.773546Z"
    }
   },
   "outputs": [],
   "source": [
    "data.sort_values(by=['dayofservice','lineid','tripid','direction','progrnumber'],inplace=True)\n",
    "# data.to_csv(\"stored_queries/combined145.csv\", index=False, chunksize=500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trips information [for full route prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsdata = pd.read_csv(\"stored_queries/trips_df.csv\")\n",
    "tripsdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsdata = tripsdata[['dayofservice', 'tripid', 'lineid', 'routeid', 'direction', 'actual_arr', 'actual_dep']]\n",
    "tripsdata.dayofservice = pd.to_datetime(tripsdata.dayofservice)\n",
    "tripsdata.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:54.176825Z",
     "start_time": "2019-07-23T13:42:54.159974Z"
    }
   },
   "outputs": [],
   "source": [
    "stops = pd.read_csv(\"stop_information.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:54.244019Z",
     "start_time": "2019-07-23T13:42:54.232737Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = list(stops.columns)\n",
    "cols[0] = 'ix'\n",
    "stops.columns = cols\n",
    "stops.drop(columns=cols[0], inplace=True)\n",
    "\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:54.329499Z",
     "start_time": "2019-07-23T13:42:54.305998Z"
    }
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv(\"stored_queries/weather.csv\")\n",
    "\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:54.451519Z",
     "start_time": "2019-07-23T13:42:54.443935Z"
    }
   },
   "outputs": [],
   "source": [
    "weather.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:42:54.536135Z",
     "start_time": "2019-07-23T13:42:54.529054Z"
    }
   },
   "outputs": [],
   "source": [
    "weather.icon = weather.icon.astype('category')\n",
    "weather.dayofservice = pd.to_datetime(weather.dayofservice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import distances between stops data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_distances = pd.read_csv(\"stored_queries/distancedata.csv\", header=None)\n",
    "stop_distances.columns = ['stopid','previous_stopid','distance']\n",
    "stop_distances.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepairing Data for Combining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather and leavetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:43:03.479719Z",
     "start_time": "2019-07-23T13:43:02.888810Z"
    }
   },
   "outputs": [],
   "source": [
    "# leavetimes data\n",
    "data.plannedARR = data.dayofservice + pd.to_timedelta(data.plannedARR, unit = 'seconds') # in nanoseconds\n",
    "data.plannedDEP = data.dayofservice + pd.to_timedelta(data.plannedDEP, unit = 'seconds') # in nanoseconds\n",
    "data.actualARR = data.dayofservice + pd.to_timedelta(data.actualARR, unit = 'seconds') # in nanoseconds\n",
    "data.actualDEP = data.dayofservice + pd.to_timedelta(data.actualDEP, unit = 'seconds') # in nanoseconds\n",
    "\n",
    "# new columns for combining\n",
    "data['time_at_stop'] = data.actualDEP - data.actualARR\n",
    "data['weather_merge_time'] = data.actualARR.dt.round('H') #  .dt useful\n",
    "\n",
    "\n",
    "# weather data\n",
    "weather.dayofservice = weather.dayofservice + pd.to_timedelta(weather.hour, unit='hour')\n",
    "\n",
    "# new column for combining\n",
    "weather['rkey'] = weather.dayofservice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trips data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsdata.actual_arr = tripsdata.dayofservice + pd.to_timedelta(tripsdata.actual_arr, unit='seconds')\n",
    "tripsdata.actual_dep = tripsdata.dayofservice + pd.to_timedelta(tripsdata.actual_dep, unit='seconds')\n",
    "tripsdata['triplength'] = tripsdata.actual_arr - tripsdata.actual_dep\n",
    "tripsdata['leavehour'] = tripsdata.actual_dep.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining weather and leavetimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:43:07.234203Z",
     "start_time": "2019-07-23T13:43:06.439577Z"
    }
   },
   "outputs": [],
   "source": [
    "combinedata = data.merge(weather[['icon','temperature','humidity','windSpeed','rain','rkey','hour']], \n",
    "                         left_on='weather_merge_time', \n",
    "                         right_on='rkey', \n",
    "                         how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:43:07.894094Z",
     "start_time": "2019-07-23T13:43:07.518939Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# drop lineid as all are 145\n",
    "combinedata.drop(columns=['rkey','lineid','weather_merge_time','plannedDEP','plannedARR','time_at_stop','actualDEP'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining trips and weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripsdata['weather_merge_time'] = tripsdata.actual_dep.dt.round('H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedtrip = tripsdata.merge(weather[['icon','temperature','humidity','windSpeed','rain','rkey','hour']], \n",
    "                               left_on='weather_merge_time', \n",
    "                               right_on='rkey', \n",
    "                               how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning / Adding Additional features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### weekday vs weekend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:43:13.351698Z",
     "start_time": "2019-07-23T13:43:13.185519Z"
    }
   },
   "outputs": [],
   "source": [
    "combinedata['weekend'] = combinedata.dayofservice.dt.weekday.isin([5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedata['holiday'] = combinedata.dayofservice.apply(lambda x: x in ie_holidays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove inactive stops from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_stopids = stops.stopid.values\n",
    "\n",
    "# remove all inactive stops from the dataset. -> additional models that arent needed. \n",
    "combinedata = combinedata[combinedata.stopid.isin(active_stopids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair Consecutive Stop IDs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous stopid\n",
    "previousstops =  list(combinedata.stopid)\n",
    "previousstops = np.array(previousstops[:-1]).astype(int)\n",
    "\n",
    "# progrnumber of previous stopid\n",
    "previousstops_progrnumber = list(combinedata.progrnumber)\n",
    "previousstops_progrnumber = np.array(previousstops_progrnumber[:-1]).astype(int)\n",
    "\n",
    "# Actual arrival time of previous stopid\n",
    "previousstops_actualARR = list(combinedata.actualARR)\n",
    "previousstops_actualARR = np.array(previousstops_actualARR[:-1])\n",
    "\n",
    "# Delete the first row of the dataframe to shift the progrnumbers by one. \n",
    "combinedata = combinedata.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedata['previous_stopid'] = previousstops\n",
    "combinedata['previous_stopARR'] = previousstops_actualARR\n",
    "combinedata['previous_progrnumber'] = previousstops_progrnumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping mis-matched progrnumbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows where progrnumber==1 as the first row is currently aligned with the last row of the previous tripid.\n",
    "combinedata = combinedata[combinedata.progrnumber != 1]\n",
    "combinedata.dropna(inplace=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping non-consecutive stop combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# recast type of integer cols from float to int. \n",
    "combinedata.previous_stopid = combinedata.previous_stopid.astype(int)\n",
    "combinedata.previous_progrnumber = combinedata.previous_progrnumber.astype(int)\n",
    "\n",
    "# make progrnumber difference column and then drop anything thats not exactly 1, removes data which skips stops. \n",
    "combinedata['progrnumber_difference'] = combinedata.progrnumber - combinedata.previous_progrnumber\n",
    "\n",
    "# checking how many rows will be left. \n",
    "# combinedata.progrnumber_difference.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-consecutive stop pairs.\n",
    "combinedata = combinedata[combinedata.progrnumber_difference==1]\n",
    "\n",
    "# Remove additional columns added for this operantion\n",
    "combinedata.drop(columns=['progrnumber','previous_progrnumber','progrnumber_difference'], inplace=True);\n",
    "\n",
    "# ordering rows [and dropping irrelevant ones: direction, route_id]\n",
    "combinedata = combinedata[['dayofservice', 'tripid','stopid', 'previous_stopid', 'actualARR', 'previous_stopARR',\n",
    "                           'icon', 'temperature', 'humidity', 'windSpeed', 'rain', 'hour', 'weekend', 'holiday']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unique Stopid combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all unique stop combinations for a given lineid.\n",
    "stop_pairs = combinedata[['stopid','previous_stopid']].drop_duplicates()\n",
    "\n",
    "print(\"There are %d unique pairs of stops on line: %s\" % (stop_pairs.count()[0], data.lineid.unique()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Travel Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to seconds\n",
    "combinedata['travel_time'] = (combinedata.actualARR - combinedata.previous_stopARR).astype(int)/10**9\n",
    "\n",
    "# drop any values less than 5 seconds [assumed erroneous]\n",
    "combinedata = combinedata[combinedata.travel_time > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are %d valid pairs\" % combinedata.count()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance between stops [ === Don't run again === ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to get the distance between two stops. \n",
    "# def get_distance(start, finish):\n",
    "#     \"\"\"\n",
    "#     Distance between two (lat,lng) pairs\n",
    "    \n",
    "#     Inputs:\n",
    "#     ================================\n",
    "#     (int) start: stopid of first stop\n",
    "#     (int) finish: stopid of last stop\n",
    "    \n",
    "#     Outputs:\n",
    "#     ===============================\n",
    "#     (int) the distance in metres between the stops. \n",
    "    \n",
    "#     Notes:\n",
    "#     ===============================\n",
    "#     If there is an error, or the api fails to find the distance a value of None will be returned. \n",
    "#     \"\"\"\n",
    "#     try:\n",
    "#         begin = (stops[stops.stopid==start ]['lat'].values[0], stops[stops.stopid==start ]['lng'].values[0])\n",
    "#         end   = (stops[stops.stopid==finish]['lat'].values[0], stops[stops.stopid==finish]['lng'].values[0])\n",
    "\n",
    "#     except Exception as e:\n",
    "\n",
    "#         print(start, finish)\n",
    "#         print(repr(e)) \n",
    "#         return None\n",
    "        \n",
    "#     API_key = config.dmatrix_key #enter Google Maps API key\n",
    "#     gmaps = googlemaps.Client(key=API_key)\n",
    "    \n",
    "#     try:\n",
    "#         call = gmaps.distance_matrix(begin, end, mode='walking')\n",
    "    \n",
    "#     except Exception as eL:\n",
    "        \n",
    "#         print(repr(eL))\n",
    "#         return None\n",
    "    \n",
    "#     status = call['status']\n",
    "    \n",
    "#     if status=='OK':\n",
    "#         return call[\"rows\"][0][\"elements\"][0]['distance']['value']\n",
    "    \n",
    "#     else:\n",
    "#         print(status)\n",
    "#         return None\n",
    "\n",
    "# distances_list = []\n",
    "\n",
    "# for index, pair in tqdm_notebook(stop_pairs.iterrows(), total=stop_pairs.shape[0]):\n",
    "\n",
    "# # for pair in stop_pairs.iterrows():\n",
    "# #     start_stopid, finish_stopid = pair[1]\n",
    "\n",
    "#     start_stopid, finish_stopid = pair[0], pair[1]\n",
    "#     distances_list.append(get_distance(start_stopid, finish_stopid))\n",
    "    \n",
    "# distance_array = np.array(distances_list)\n",
    "\n",
    "# stop_pairs['distance'] = distance_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combinedata = combinedata.merge(stop_distances, how='left', left_on=['stopid','previous_stopid'], right_on=['stopid','previous_stopid'])\n",
    "combinedata.distance = combinedata.distance.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking average speed as distance / time (km/h)\n",
    "combinedata['avgvel'] = (combinedata.distance / combinedata.travel_time) * (3600/1000)\n",
    "\n",
    "# Note need to drop all data over 120 km/h -> erroneous data\n",
    "combinedata = combinedata[combinedata.avgvel <= 120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traffic variance / effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# add in later for clustering purposes\n",
    "# combinedata['variance'] := score based on the two stops and effect traffic has on the travel time\n",
    "\n",
    "combinedata[(combinedata.stopid==1476)&(combinedata.previous_stopid==4320)]['avgvel'].hist(bins=100)\n",
    "plt.xlim([0,100])\n",
    "\n",
    "\n",
    "# Note need to drop all data over 120 km/h -> erroneous data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing outliers [=== Do this in the model training section as it will need to be done for each pair ===]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on Time Spent at stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-23T13:27:15.438874Z",
     "start_time": "2019-07-23T13:27:15.330000Z"
    }
   },
   "outputs": [],
   "source": [
    "# combinedata.time_at_stop.astype(int).apply(lambda x: x*10**-9).hist(bins=1000) # hitogram of times spent at a stop. \n",
    "# combinedata.time_at_stop = combinedata.time_at_stop.astype(int) / 10**9\n",
    "# combinedata.head()\n",
    "\n",
    "# use this one\n",
    "## combinedata.travel_time.astype(int).hist(bins=10000) # hitogram of times spent at a stop. \n",
    "## plt.xlim([0,300])\n",
    "\n",
    "# combinedata[combinedata['time_at_stop'] != 0].boxplot(column= ['time_at_stop'])\n",
    "# combinedata.time_at_stop.describe().astype(int)\n",
    "\n",
    "# Will use 3$\\sigma$ as the threshold for outliers <br>\n",
    "# Note: This method can fail to detect outliers because the outliers increase the standard deviation.\n",
    "\n",
    "# # df[(np.abs(stats.zscore(df)) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Month/Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedata['month'] = combinedata.dayofservice.dt.month\n",
    "\n",
    "def set_season(x):\n",
    "    winter = [11,12,1]\n",
    "    autumn = [10,9,8]\n",
    "    spring = [4,3,2]\n",
    "\n",
    "    if x in winter:\n",
    "        return 'Winter'\n",
    "    elif x in autumn:\n",
    "        return 'Autumn'\n",
    "    elif x in spring:\n",
    "        return 'Spring'\n",
    "    else:\n",
    "        return 'Summer'\n",
    "    \n",
    "combinedata['season'] = combinedata.dayofservice.dt.month.apply(set_season)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Season Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedata.season = combinedata.season.astype('category', categories=['Summer','Spring','Autumn','Winter'])\n",
    "\n",
    "combinedata = pd.concat([combinedata, pd.get_dummies(combinedata.season, prefix='season')], axis=1)\n",
    "combinedata.drop(columns=['season'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Icon Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedata.icon = combinedata.icon.astype('category', categories=['partly-cloudy-day', 'partly-cloudy-night', 'clear-day', 'clear-night', 'rain', 'fog', 'cloudy', 'wind'])\n",
    "\n",
    "combinedata = pd.concat([combinedata, pd.get_dummies(combinedata.icon, prefix='icon')], axis=1)\n",
    "combinedata.drop(columns=['icon'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop all N/A values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedata = combinedata.dropna() # drop na values. \n",
    "combinedata.dtypes\n",
    "\n",
    "print(\"There are %d valid pairs\" % combinedata.count()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinedata.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata = combinedata[['travel_time','stopid','previous_stopid',\n",
    "                         'temperature','humidity', 'windSpeed', 'rain', 'hour', 'holiday', 'weekend',\n",
    "                         'month','season_Winter','season_Autumn','season_Summer','season_Spring',\n",
    "                         'icon_clear-day', 'icon_clear-night', 'icon_cloudy', 'icon_fog',\n",
    "                         'icon_partly-cloudy-day', 'icon_partly-cloudy-night', 'icon_rain','icon_wind']]\n",
    "modeldata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in unique_coordinates.iterrows():\n",
    "    stop_A = row[1][1]\n",
    "    stop_B = row[1][0]\n",
    "    break\n",
    "    \n",
    "(stop_A, stop_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata = combinedata[combinedata.stopid==stop_B]\n",
    "modeldata = modeldata[modeldata.previous_stopid==stop_A]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are %d rows relating to pair (%d, %d)\" % (modeldata.count()[0], stop_A, stop_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put this in a loop over the pairs of stops. (unique)\n",
    "target     = ['travel_time']\n",
    "predictors = ['temperature','humidity', 'windSpeed', 'rain', 'hour', 'holiday', 'weekend',\n",
    "              'month','season_Winter','season_Autumn','season_Summer','season_Spring',\n",
    "              'icon_clear-day', 'icon_clear-night', 'icon_cloudy', 'icon_fog',\n",
    "              'icon_partly-cloudy-day', 'icon_partly-cloudy-night', 'icon_rain','icon_wind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata.travel_time.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "travel_time_deviation = modeldata.travel_time.std()\n",
    "\n",
    "# ERRORS HERE fixed,  - no\n",
    "# 2 sigma - 95% of data\n",
    "modeldata = modeldata[abs(modeldata.travel_time-modeldata.travel_time.mean()) < 3*travel_time_deviation]\n",
    "modeldata = modeldata[modeldata.travel_time >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata.travel_time.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeldata.travel_time.hist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(modeldata, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RFM = RandomForestClassifier(n_estimators=100, max_features='auto', oob_score=True, random_state=1)\n",
    "RFM.fit(train[predictors], train[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature':predictors, 'importance': RFM.feature_importances_})\n",
    "\n",
    "feature_importance.set_index('feature', inplace=True)\n",
    "feature_importance.plot.barh(title='Feature importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFM_predictions = RFM.predict(test[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(RFM_predictions - test.travel_time, bins=20, density=True)\n",
    "\n",
    "\n",
    "# # best fit of data\n",
    "(mu, sigma) = stats.norm.fit(RFM_predictions - test.travel_time)\n",
    "\n",
    "# # the histogram of the data\n",
    "# n, bins, patches = plt.hist(RFM_predictions - test.travel_time, 2000, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "# add a 'best fit' line\n",
    "# y = mlab.normpdf(bins, mu, sigma)\n",
    "l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "plt.show()\n",
    "\n",
    "print(sigma, mu)\n",
    "\n",
    "test.travel_time.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE\n",
    "trips_145_FILTERED = trips_145.dropna()\n",
    "\n",
    "rmse_arrival_full = np.sqrt(metrics.mean_squared_error(trips_145_FILTERED.planned_arr.astype(int), trips_145_FILTERED.actual_arr.astype(int)))\n",
    "rmse_depart_full  = np.sqrt(metrics.mean_squared_error(trips_145_FILTERED.planned_dep.astype(int), trips_145_FILTERED.actual_dep.astype(int)))\n",
    "\n",
    "average_trip = (trips_145_FILTERED.actual_arr.astype(int) - trips_145_FILTERED.actual_dep.astype(int)).mean()\n",
    "\n",
    "print(f\"\"\"\n",
    "\n",
    "Full Trip:\n",
    "Average Trip length: {round(average_trip,2)}s [{round(average_trip/3600,2)}h]\n",
    "\n",
    "RMSE Arrival time:   {round(rmse_arrival_full,2)}s  [{round(100*(rmse_arrival_full/average_trip),2)}%] \n",
    "RMSE Departure time: {round(rmse_depart_full,2)}s  [{round(100*(rmse_depart_full/average_trip),2)}%]\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "447.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
